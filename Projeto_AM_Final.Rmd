---
title: "Projeto AM Final"
output: html_notebook
---


Package install

```{r}
# Install Libraries ---------------------------------------------------------------

install.packages('readr')
install.packages('dplyr')
install.packages('psych')
install.packages('ggplot2')
install.packages('tidyverse')
install.packages('ggcorrplot')
install.packages('readxl')
##
install.packages('plyr')
install.packages('dummies')
install.packages('ROSE')
install.packages('splitstackshape')
install.packages('XML')
install.packages('mlr')
install.packages('PCAmixdata')
```

Data Prep

```{r}
# Load Libraries ----------------------------------------------------------

library('readr')
library('readxl')
library('dplyr')
library('plyr')
library('psych')
library('ggplot2')
library('tidyverse')
library('ggcorrplot')
library('PCAmixdata')
library('dummies')
library('ROSE')
library('splitstackshape')
library('mlr')

# Main --------------------------------------------------------------------

original_file <- read.csv(file.choose(), skip=1)


# number of rows and columns
n_rows = nrow(original_file)
n_cols = ncol(original_file)

# remove id column
df <- subset(original_file, select = -c(ID))

# rename columns
df <- dplyr::rename(df,credit_limit = LIMIT_BAL,gender = SEX, education = EDUCATION, marital_status = MARRIAGE, age = AGE, payment_status_sept = PAY_0, payment_status_aug = PAY_2, payment_status_jul = PAY_3, payment_status_jun = PAY_4, payment_status_may = PAY_5, payment_status_apr = PAY_6, bill_sept = BILL_AMT1, bill_aug = BILL_AMT2, bill_jul = BILL_AMT3, bill_jun = BILL_AMT4, bill_may = BILL_AMT5, bill_apr = BILL_AMT6, payment_amount_sept = PAY_AMT1, payment_amount_aug = PAY_AMT2, payment_amount_jul = PAY_AMT3, payment_amount_jun = PAY_AMT4, payment_amount_may = PAY_AMT5, payment_amount_apr = PAY_AMT6, default_payment = 'default.payment.next.month')

# Statistics of features
a <-describe(df)
write.csv(a,"summary.csv", row.names = TRUE)


## Exploratory Analysis ##

# fix the problem of no consumption customers having default payment next month
df$default_payment[df$bill_apr == 0 & df$bill_may == 0 & df$bill_jun == 0 & df$bill_jul == 0 & df$bill_aug == 0 & df$bill_sept == 0 & df$default_payment == 1] <- 0


# Bar plot - # clients by default or not in payment
ggplot(data = df, aes(x = factor(default_payment), fill=factor(default_payment), label = scales::percent(prop.table(stat(count))))) +
  geom_bar(stat="count", position=position_dodge()) +
  geom_text(stat = 'count',
            position = position_dodge(.9), 
            vjust = -0.25, 
            size = 3,
            format_string="{:.1f}%") + 
  geom_text(stat = 'count',aes(label=..count..),
            position = position_dodge(.9), 
            vjust = 5, 
            size = 3, color="white") +
  scale_fill_manual(name = "", values=c("lightblue", "steelblue"), labels=c("Non-default","Default")) +
  labs( title = "Default Credit Card Clients - Default payment next month")+
  labs(x = 'default_payment', y = '# number of clients', fill = 'default_payment')

# Bar plot - # credit limit by dpnm
credit_bin <- cut(df$credit_limit, breaks=c(5000,50000,100000,150000,200000,300000,400000,500000,1100000), right=TRUE)

ggplot(data=df, aes(x=factor(credit_bin), fill=factor(default_payment), label = stat(count)) ) +
  geom_bar(stat="count", position=position_dodge()) + 
  geom_text(stat = 'count', position = position_dodge(.9), vjust = -0.5, size = 3) + 
  labs( title = "Default Credit Card Clients - Default payment next month")+
  scale_fill_manual(name = "", values=c("lightblue", "steelblue"), labels=c("Non-default","Default")) +
  labs(x = 'Amount of given credit', y = '# number of clients', fill = 'default_payment')+ scale_x_discrete(labels=c("[5k,50k]","[50k,100k]", "[100k,150k]", "[150k,200k]", "[200k,300k]", "[300k,400k]", "[400k,500k]", "[500k,1.1M]"))

ggplot(data=df, aes(x = Class, fill = Survived, weight = Freq, by = Class)) +
  stat_prop(position = "fill") +
  geom_text(stat = "prop", position = position_fill(.5))

# Bar plot - # clients by age
age_bin <- cut(df$age, breaks=c(20,30,40,50,60,70,80), right=TRUE)

ggplot(data=df, aes(x=factor(age_bin), fill=factor(default_payment), label = stat(count))) +
  geom_bar(stat="count", position=position_dodge()) +
  geom_text(stat = 'count',
            position = position_dodge(.9), 
            vjust = -0.5, 
            size = 3) + 
  labs( title = "Age - Default payment next month")+
  scale_fill_manual(name = "", values=c("lightblue", "steelblue"), labels=c("Non-default","Default")) +
  labs(x = 'Age', y = '# number of clients', fill = 'default_payment')+ scale_x_discrete(labels=c("[20,30]","[30,40]", "[40,50]", "[50,60]", "[60,70]", "[70,80]"))

# Bar plot - # clients by gender
ggplot(data=df, aes(x=factor(gender), fill=factor(default_payment), label = scales::percent(prop.table(stat(count))))) +
  geom_bar(stat="count", position=position_dodge()) +
  geom_text(stat = 'count',
            position = position_dodge(.9), 
            vjust = -0.5, 
            size = 3) + 
  labs( title = "Gender - Default payment next month")+
  scale_fill_manual(name = "", values=c("lightblue", "steelblue"), labels=c("Non-default","Default")) +
  labs(x = 'Gender', y = '# number of clients', fill = 'default_payment') + scale_x_discrete(labels=c("Female","Male"))

# Order marital status levels
df$marital_status <- factor(df$marital_status, levels=c("0", "2", "1", "3"))

# Bar plot - # clients by Marital Status
ggplot(data=df, aes(x=factor(marital_status), fill=factor(default_payment), label = scales::percent(prop.table(stat(count))))) +
  geom_bar(stat="count", position=position_dodge()) +
  geom_text(stat = 'count',
            position = position_dodge(.9), 
            vjust = -0.5, 
            size = 3) + 
  labs( title = "Marital Status - Default payment next month")+
  scale_fill_manual(name = "", values=c("lightblue", "steelblue"), labels=c("Non-default","Default")) +
  labs(x = 'Marital Status', y = '# number of clients', fill = 'default_payment')+ scale_x_discrete(labels=c("Single","Married", "Divorced", "Unknown"))

# Variable 'education': group the categories 0, 4, 5, 6 into a single class '0' (others)
df$education[ df$education == 4 | df$education == 5 | df$education == 6] <- 0

# Order education levels
df$education <- factor(df$education, levels=c("3","2","1","0"))

# Bar plot - # clients by Education Level
ggplot(data=df, aes(x=factor(education), fill=factor(default_payment), label = scales::percent(prop.table(stat(count))))) +
  geom_bar(stat="count", position=position_dodge()) +
  geom_text(stat = 'count',
            position = position_dodge(.9), 
            vjust = -0.5, 
            size = 3) +
  labs( title = "Education Level - Default payment next month")+
  scale_fill_manual(name = "", values=c("lightblue", "steelblue"), labels=c("Non-default","Default")) +
  labs(x = 'Education', y = '# number of clients', fill = 'default_payment') + scale_x_discrete(labels=c("High School", "University", "Graduate School","Others","Unknown"))

#Plot payment amounts variation over months

ggplot(df, aes(x = bill_apr, y = payment_amount_may)) +
  geom_point()

ggplot(df, aes(x = bill_may, y = payment_amount_jun)) +
  geom_point()

ggplot(df, aes(x = bill_jun, y = payment_amount_jul)) +
  geom_point()

ggplot(df, aes(x = bill_jul, y = payment_amount_aug)) +
  geom_point()

ggplot(df, aes(x = bill_aug, y = payment_amount_sept)) +
  geom_point()

##################################
##################################

#### One-hot encoding - START ####

# one-hot-encoding of gender, marital status and education
gender_encode <- cbind(df$gender, dummy(df$gender, sep='_'))
marital_status_encode <- cbind(df$marital_status, dummy(df$marital_status, sep='_'))
education_encode <- cbind(df$education, dummy(df$education, sep='_'))

# regrouping of columns of previous data frames
gender_encode <- gender_encode[ , c("gender_1", "gender_2")]
education_encode <- education_encode[ , c("education_0", "education_1", "education_2", "education_3", "education_4")]
marital_status_encode <- marital_status_encode[ , c("marital_status_1", "marital_status_2", "marital_status_3", "marital_status_0")]

# data file with gender, marital status and education encoded
df_ohe1 <- cbind(df[1], gender_encode, education_encode, marital_status_encode, df[5:24])

# one-hot-encoding of all payment_status
status_sep_encode <- cbind(df_ohe1$payment_status_sept, dummy(df_ohe1$payment_status_sept, sep='_'))
status_aug_encode <- cbind(df_ohe1$payment_status_aug, dummy(df_ohe1$payment_status_aug, sep='_'))
status_jul_encode <- cbind(df_ohe1$payment_status_jul, dummy(df_ohe1$payment_status_jul, sep='_'))
status_jun_encode <- cbind(df_ohe1$payment_status_jun, dummy(df_ohe1$payment_status_jun, sep='_'))
status_may_encode <- cbind(df_ohe1$payment_status_may, dummy(df_ohe1$payment_status_may, sep='_'))
status_apr_encode <- cbind(df_ohe1$payment_status_apr, dummy(df_ohe1$payment_status_apr, sep='_'))

# regrouping of columns of previous data frames
status_sep_encode <- status_sep_encode[ , c("payment_status_sept_-2", "payment_status_sept_-1", "payment_status_sept_0", "payment_status_sept_1", "payment_status_sept_2", "payment_status_sept_3", "payment_status_sept_4", "payment_status_sept_5", "payment_status_sept_6", "payment_status_sept_7", "payment_status_sept_8")]
status_aug_encode <- status_aug_encode[ , c("payment_status_aug_-2", "payment_status_aug_-1", "payment_status_aug_0", "payment_status_aug_1", "payment_status_aug_2", "payment_status_aug_3", "payment_status_aug_4", "payment_status_aug_5", "payment_status_aug_6", "payment_status_aug_7", "payment_status_aug_8")]
status_jul_encode <- status_jul_encode[ , c("payment_status_jul_-2", "payment_status_jul_-1", "payment_status_jul_0", "payment_status_jul_1", "payment_status_jul_2", "payment_status_jul_3", "payment_status_jul_4", "payment_status_jul_5", "payment_status_jul_6", "payment_status_jul_7", "payment_status_jul_8")]
status_jun_encode <- status_jun_encode[ , c("payment_status_jun_-2", "payment_status_jun_-1", "payment_status_jun_0", "payment_status_jun_1", "payment_status_jun_2", "payment_status_jun_3", "payment_status_jun_4", "payment_status_jun_5", "payment_status_jun_7", "payment_status_jun_8")]
status_may_encode <- status_may_encode[ , c("payment_status_may_-2", "payment_status_may_-1", "payment_status_may_0", "payment_status_may_2", "payment_status_may_3", "payment_status_may_4", "payment_status_may_5", "payment_status_may_7")]
status_apr_encode <- status_apr_encode[ , c("payment_status_apr_-2", "payment_status_apr_-1", "payment_status_apr_0", "payment_status_apr_2", "payment_status_apr_3", "payment_status_apr_4", "payment_status_apr_5", "payment_status_apr_6", "payment_status_apr_7")]


# df_ohe_final: data file with gender, marital status education and all payment status encoded
df_ohe_final <- cbind(df_ohe1[1:13], status_sep_encode, status_aug_encode, status_jul_encode, status_jun_encode, status_may_encode, status_apr_encode, df_ohe1[20:32])
# renaming of payment_status columns _-2 to _neg2 and _-1 to _neg1: the .._-2 and .._-1 gives error in sampling functions
names(df_ohe_final) <- c("credit_limit", "gender_1", "gender_2", "education_1", "education_2", "education_3", "education_4", "education_5", "marital_status_1", "marital_status_2", "marital_status_3", "marital_status_0", "age", "payment_status_sept_neg2", "payment_status_sept_neg1", "payment_status_sept_0", "payment_status_sept_1", "payment_status_sept_2", "payment_status_sept_3", "payment_status_sept_4", "payment_status_sept_5", "payment_status_sept_6", "payment_status_sept_7", "payment_status_sept_8", "payment_status_aug_neg2", "payment_status_aug_neg1", "payment_status_aug_0", "payment_status_aug_1", "payment_status_aug_2", "payment_status_aug_3", "payment_status_aug_4", "payment_status_aug_5", "payment_status_aug_6", "payment_status_aug_7", "payment_status_aug_8", "payment_status_jul_neg2", "payment_status_jul_neg1", "payment_status_jul_0", "payment_status_jul_1", "payment_status_jul_2", "payment_status_jul_3", "payment_status_jul_4", "payment_status_jul_5", "payment_status_jul_6", "payment_status_jul_7", "payment_status_jul_8", "payment_status_jun_neg2", "payment_status_jun_neg1", "payment_status_jun_0", "payment_status_jun_1", "payment_status_jun_2", "payment_status_jun_3", "payment_status_jun_4", "payment_status_jun_5", "payment_status_jun_7", "payment_status_jun_8", "payment_status_may_neg2", "payment_status_may_neg1", "payment_status_may_0", "payment_status_may_2", "payment_status_may_3", "payment_status_may_4", "payment_status_may_5", "payment_status_may_7", "payment_status_apr_neg2", "payment_status_apr_neg1", "payment_status_apr_0", "payment_status_apr_2", "payment_status_apr_3", "payment_status_apr_4", "payment_status_apr_5", "payment_status_apr_6", "payment_status_apr_7", "bill_sept", "bill_aug", "bill_jul", "bill_jun", "bill_may", "bill_apr", "payment_amount_sept", "payment_amount_aug", "payment_amount_jul", "payment_amount_jun", "payment_amount_may", "payment_amount_apr", "default_payment")

#### One-hot encoding - END ####

################################
################################


# Prepare correlations plotting
df_aux <-df_ohe_final

#Turn categorical variables to numeric
df_aux$gender_1 <- as.numeric(df_aux$gender_1)
df_aux$gender_2 <- as.numeric(df_aux$gender_2)
df_aux$education_1 <- as.numeric(df_aux$education_1)
df_aux$education_2 <- as.numeric(df_aux$education_2)
df_aux$education_3 <- as.numeric(df_aux$education_3)
df_aux$education_4 <- as.numeric(df_aux$education_4)
df_aux$education_5 <- as.numeric(df_aux$education_5)
df_aux$marital_status_1 <- as.numeric(df_aux$marital_status_1)
df_aux$marital_status_2 <- as.numeric(df_aux$marital_status_2)
df_aux$marital_status_3 <- as.numeric(df_aux$marital_status_3)
df_aux$marital_status_0 <- as.numeric(df_aux$marital_status_0)
df_aux$age <- as.numeric(df_aux$age)
df_aux$payment_status_sept_neg2 <- as.numeric(df_aux$payment_status_sept_neg2)
df_aux$payment_status_sept_neg1 <- as.numeric(df_aux$payment_status_sept_neg1)
df_aux$payment_status_sept_0 <- as.numeric(df_aux$payment_status_sept_0)
df_aux$payment_status_sept_1 <- as.numeric(df_aux$payment_status_sept_1)
df_aux$payment_status_sept_2 <- as.numeric(df_aux$payment_status_sept_2)
df_aux$payment_status_sept_3 <- as.numeric(df_aux$payment_status_sept_3)
df_aux$payment_status_sept_4 <- as.numeric(df_aux$payment_status_sept_4)
df_aux$payment_status_sept_5 <- as.numeric(df_aux$payment_status_sept_5)
df_aux$payment_status_sept_6 <- as.numeric(df_aux$payment_status_sept_6)
df_aux$payment_status_sept_7 <- as.numeric(df_aux$payment_status_sept_7)
df_aux$payment_status_sept_8 <- as.numeric(df_aux$payment_status_sept_8)

df_aux$payment_status_aug_neg2 <- as.numeric(df_aux$payment_status_aug_neg2)
df_aux$payment_status_aug_neg1 <- as.numeric(df_aux$payment_status_aug_neg1)
df_aux$payment_status_aug_0 <- as.numeric(df_aux$payment_status_aug_0)
df_aux$payment_status_aug_1 <- as.numeric(df_aux$payment_status_aug_1)
df_aux$payment_status_aug_2 <- as.numeric(df_aux$payment_status_aug_2)
df_aux$payment_status_aug_3 <- as.numeric(df_aux$payment_status_aug_3)
df_aux$payment_status_aug_4 <- as.numeric(df_aux$payment_status_aug_4)
df_aux$payment_status_aug_5 <- as.numeric(df_aux$payment_status_aug_5)
df_aux$payment_status_aug_6 <- as.numeric(df_aux$payment_status_aug_6)
df_aux$payment_status_aug_7 <- as.numeric(df_aux$payment_status_aug_7)

df_aux$payment_status_jul_neg2 <- as.numeric(df_aux$payment_status_jul_neg2)
df_aux$payment_status_jul_neg1 <- as.numeric(df_aux$payment_status_jul_neg1)
df_aux$payment_status_jul_0 <- as.numeric(df_aux$payment_status_jul_0)
df_aux$payment_status_jul_1 <- as.numeric(df_aux$payment_status_jul_1)
df_aux$payment_status_jul_2 <- as.numeric(df_aux$payment_status_jul_2)
df_aux$payment_status_jul_3 <- as.numeric(df_aux$payment_status_jul_3)
df_aux$payment_status_jul_4 <- as.numeric(df_aux$payment_status_jul_4)
df_aux$payment_status_jul_5 <- as.numeric(df_aux$payment_status_jul_5)
df_aux$payment_status_jul_6 <- as.numeric(df_aux$payment_status_jul_6)
df_aux$payment_status_jul_7 <- as.numeric(df_aux$payment_status_jul_7)

df_aux$payment_status_jun_neg2 <- as.numeric(df_aux$payment_status_jun_neg2)
df_aux$payment_status_jun_neg1 <- as.numeric(df_aux$payment_status_jun_neg1)
df_aux$payment_status_jun_0 <- as.numeric(df_aux$payment_status_jun_0)
df_aux$payment_status_jun_1 <- as.numeric(df_aux$payment_status_jun_1)
df_aux$payment_status_jun_2 <- as.numeric(df_aux$payment_status_jun_2)
df_aux$payment_status_jun_3 <- as.numeric(df_aux$payment_status_jun_3)
df_aux$payment_status_jun_4 <- as.numeric(df_aux$payment_status_jun_4)
df_aux$payment_status_jun_5 <- as.numeric(df_aux$payment_status_jun_5)
df_aux$payment_status_jun_7 <- as.numeric(df_aux$payment_status_jun_7)
df_aux$payment_status_jun_8 <- as.numeric(df_aux$payment_status_jun_8)

df_aux$payment_status_may_neg2 <- as.numeric(df_aux$payment_status_may_neg2)
df_aux$payment_status_may_neg1 <- as.numeric(df_aux$payment_status_may_neg1)
df_aux$payment_status_may_0 <- as.numeric(df_aux$payment_status_may_0)
df_aux$payment_status_may_2 <- as.numeric(df_aux$payment_status_may_2)
df_aux$payment_status_may_3 <- as.numeric(df_aux$payment_status_may_3)
df_aux$payment_status_may_4 <- as.numeric(df_aux$payment_status_may_4)
df_aux$payment_status_may_5 <- as.numeric(df_aux$payment_status_may_5)
df_aux$payment_status_may_7 <- as.numeric(df_aux$payment_status_may_7)

df_aux$payment_status_apr_neg2 <- as.numeric(df_aux$payment_status_apr_neg2)
df_aux$payment_status_apr_neg1 <- as.numeric(df_aux$payment_status_apr_neg1)
df_aux$payment_status_apr_0 <- as.numeric(df_aux$payment_status_apr_0)
df_aux$payment_status_apr_2 <- as.numeric(df_aux$payment_status_apr_2)
df_aux$payment_status_apr_3 <- as.numeric(df_aux$payment_status_apr_3)
df_aux$payment_status_apr_4 <- as.numeric(df_aux$payment_status_apr_4)
df_aux$payment_status_apr_5 <- as.numeric(df_aux$payment_status_apr_5)
df_aux$payment_status_apr_6 <- as.numeric(df_aux$payment_status_apr_6)
df_aux$payment_status_apr_7 <- as.numeric(df_aux$payment_status_apr_7)

df_aux$default_payment <- as.numeric(df_aux$default_payment)

str(df_aux)

# Plot correlations
corr_mat<- cor(df_aux)
ggcorrplot(corr_mat)
###################################################
###################################################
###################################################
#OHE2


ordinalvars = c("gender","education","marital_status","payment_status_sept","payment_status_aug", "payment_status_jul",
                "payment_status_jun","payment_status_may","payment_status_may","payment_status_apr")

df_new <- df
for (i in ordinalvars){
  df_new[,i] = as.factor(df[,i])
}

df_dummies <- createDummyFeatures(df_new, method = "reference")


###################################################
###################################################
###################################################
#names_factor<- c(2:12,14:73,86)
names_factor<- c(15:80)
df_factor <- df_dummies[,names_factor]
percentagens<-c(1:80)

for(i in c(1:80)){percentagens[i]<-sum(df_dummies[,i])/30000}

qplot(c(1:80), percentagens) + 
  geom_line() + 
  ylim(0, 0.001)

n_indices_below=0
for(i in c(1:80)){
  if(sum(df_dummies[,i])/30000<0.001){
    n_indices_below=n_indices_below+1
  }
}

indices_below=c()
for(i in c(1:80)){
  if(sum(df_dummies[,i])/30000<0.01){
    indices_below<-append(indices_below,i)
  }
}

n_indicies_below=length(indices_below)
indices_below

df_dummies<-df_dummies[,-indices_below]


###################################################
###################################################
###################################################
## Standardize numeric variables
df_dummies$credit_limit = scale(df_dummies$credit_limit)
df_dummies$age = scale(df_dummies$age)
df_dummies$bill_apr = scale(df_dummies$bill_apr)
df_dummies$bill_may = scale(df_dummies$bill_may)
df_dummies$bill_jun = scale(df_dummies$bill_jun)
df_dummies$bill_jul = scale(df_dummies$bill_jul)
df_dummies$bill_aug = scale(df_dummies$bill_aug)
df_dummies$bill_sept = scale(df_dummies$bill_sept)
df_dummies$payment_amount_apr = scale(df_dummies$payment_amount_apr)
df_dummies$payment_amount_may = scale(df_dummies$payment_amount_may)
df_dummies$payment_amount_jun = scale(df_dummies$payment_amount_jun)
df_dummies$payment_amount_jul = scale(df_dummies$payment_amount_jul)
df_dummies$payment_amount_aug = scale(df_dummies$payment_amount_aug)
df_dummies$payment_amount_sept = scale(df_dummies$payment_amount_sept)



###################################################
###################################################
###################################################




#PCA
#######################
#######################
#######################


data <- df_dummies
#data <- data[,-length(data)]

#Without dummies (df)
#names_numeric <-c(1,12:23)
#names_factor <-c(2:11, 24)

#With dummies (df_aux)
#names_numeric <-c(1,13,74:85)
#names_factor <-c(2:12,14:73,86)
df.pre.pca.x <- df_dummies[,-15]
df.pre.pca.y <- df_dummies$default_payment

#With dummires(df_dummies)##Ignore for now
names_factor <-c(15:42)
names_numeric<-c(1:14)

df.pre.pca.x[,names_factor] <- lapply(df.pre.pca.x[,names_factor] , factor)
df.pre.pca.x[,names_numeric] <- lapply(df.pre.pca.x[,names_numeric], as.numeric)

data_numeric <- df.pre.pca.x[,names_numeric]
data_nominal <- df.pre.pca.x[,names_factor]
data_nominal <- as.data.frame(lapply(data_nominal,factor))

data.pca <- prcomp(data, center = TRUE,scale. = TRUE)

summary(data.pca)

str(data.pca)

#Screen Plot
var_explained = data.pca$sdev^2 / sum(data.pca$sdev^2)

qplot(c(1:13), var_explained) + 
  geom_line() + 
  xlab("PCA") + 
  ylab("Variance Explained") +
  ggtitle("Screen Plot") +
  ylim(0, )

print(var_explained)

#################################
#Mixed PCA#
#https://nextjournal.com/pc-methods/calculate-pc-mixed-data




res.pcamix <- PCAmix(X.quanti=data_numeric,  
                     X.quali=data_nominal, 
                     rename.level=TRUE, 
                     graph=FALSE, 
                     ndim=42)

#Inspect PCA
summary(res.pcamix)

res.pcamix$eig

res.pcamix$sqload

ggplot2::qplot(c(1:42), res.pcamix$eig[c(1:42), 3]/100) + 
  geom_line() + 
  xlab("PCA") + 
  ylab("Cumulative Variance Explained") +
  ggtitle("Screen Plot") +
  ylim(0, 1)

##Use only the first n components
n=17

loadings<-data.frame(matrix(NA, nrow = 42, ncol = 42))

#speedup
coeficientes <- res.pcamix$coef

for(i in 1:42){
  for(j in 1:42){
    if(coeficientes[[i]][j]<0.001){
      loadings[j,i]<-0}
    else{loadings[j,i]<-round(coeficientes[[i]][j],3)}
  }
}

vector<-c(1:42)
for(i in 1:42){
  vector[i]<-loadings[i,10]
}
norm(vector,type="2")


data.pca.x <- data.frame(matrix(NA, nrow = 42, ncol = 17))

data_aux <-df.pre.pca.x

for(i in 1:17){
  for(j in 1:30000)
    data.pca.x[j,i] <-as.numeric(loadings[,i])%*%as.numeric(data_aux[j,])
}
data.pca.x

write_csv(data.pca.x,"C:\\Users\\alexr\\Documents\\after_PCA_without_default.csv")

#####-----
data_pca <-data.pca.x
data_pca <-cbind(data_pca,df.pre.pca.y) 

write_csv(data_pca,"C:\\Users\\alexr\\Documents\\after_PCA_with_default.csv")

data_pca <- dplyr::rename(data_pca,default_payment = df.pre.pca.y)

#Stratification
set.seed(12345)
df_split_dummies <- splitstackshape::stratified(data_pca, c('default_payment'), 0.8, bothSets=TRUE)

df.train <- df_split_dummies$SAMP1
df.train <- as.data.frame(df.train) # convert data.table to data.frame

df.test <- df_split_dummies$SAMP2
df.test <- as.data.frame(df.test) # convert data.table to data.frame 

#Train and test without target variable for unsupervised learning
df.train.no.default <- subset(df.train, select = -c(default_payment))

df.test.no.default <- subset(df.test, select = -c(default_payment))
library(readxl)
write.csv(df.test,"C:\\Users\\alexr\\Documents\\after_PCA_test.csv")
######################################################################
######################################################################
#Over and undersmapling

## Create a new balanced train set, with the same size of the original train set, using both under- and over sampling
df.train.balanced <- ROSE::ovun.sample(default_payment~., df.train, method="both", p=0.30, seed=12345)$data

df.train.balanced.no.default <- subset(df.train.balanced, select = -c(default_payment))
## Sanity Check!! Must be the same in the train.balanced 

### train.balanced --------------------------------
cat("train.balanced:")
#### Number of elements per class in train set
table(df.train.balanced$default_payment)
#### % of the minority class in new train set
(length(df.train.balanced["default_payment"][df.train.balanced["default_payment"] == 1]) / nrow(df.train.balanced)) * 100

##########################################################################################
###########################################################################################
```


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Models
--------------------------------------------------------------------------------------------
-Unsupervised techniques

K-Means:

```{r}
library("ggfortify")
library("ggplot2")
library(cluster) 
library(factoextra)





set.seed(1)
#Check ideal cluster number
fviz_nbclust(df.train.balanced.no.default, kmeans, method='silhouette')

km <- kmeans(df.train.balanced.no.default, centers = 4, nstart = 25)
#view results
fviz_cluster(km, data = df.train.balanced.no.default,geom = c("point"))

#Compare results
comparison_kmeans <-cbind(km$cluster,df.train.balanced$default_payment)
cluster_frequency_kmeans <- table(comparison_kmeans[,1])
dp_frequency_train <- table(comparison_kmeans[,2])
prop.table(cluster_frequency_kmeans)
prop.table(dp_frequency_train)



#MRMR

df.train.mrmr.balanced <- read.csv(file.choose())
df.train.mrmr.balanced <- subset(df.train.mrmr.balanced, select = -c(X))
df.train.mrmr.unlabeled <- read.csv(file.choose())
df.train.mrmr.unlabeled <- subset(df.train.mrmr.unlabeled, select = -c(X))
df.train.balanced <- read.csv(file.choose())
df.train.balanced <- subset(df.train.balanced, select = -c(X))
df.train.balanced.no.default <- read.csv(file.choose())
df.train.balanced.no.default <- subset(df.train.balanced.no.default, select = -c(X))
df.test <- read.csv(file.choose())
df.test <- subset(df.test, select = -c(X))

library(cluster) 
library(factoextra)

#Compute similarity matrix
gower_dist <- daisy(df.train.mrmr.unlabeled, metric = "gower")
gower_mat <- as.matrix(gower_dist)

set.seed(1)
#Check ideal cluster number
fviz_nbclust(gower_mat, kmeans, method='silhouette')



## Estimating the optimal number of clusters: Gap Statistics
fviz_nbclust(df_cluster, kmeans,diss=gower_mat, method = "gap_stat", k.max=7)

## Estimating the optimal number of clusters: WSS
fviz_nbclust(gower_mat, kmeans, method = "wss", k.max=7)

##Apply kmeans

km <- kmeans(gower_mat, centers = 2, nstart = 25)
#view results
fviz_cluster(km, data = df.train.mrmr.unlabeled,geom = c("point"))


#Compare results
comparison_kmeans <-cbind(km$cluster,df.train.mrmr.balanced$default_payment)
cluster_frequency_kmeans <- table(comparison_kmeans[,1])
dp_frequency_train <- table(comparison_kmeans[,2])
prop.table(cluster_frequency_kmeans)
prop.table(dp_frequency_train)

################################
###############################
###############################
#For classification (5)

###Use whole dataset

df.mrmr<- read.csv("df.mrmr")
df.mrmr <- df.mrmr[,-1]

###Remove labels

df.mrmr.unlabeled <-df.mrmr[,-18]

###Create similarity matrix

gower_dist <- daisy(df.mrmr.unlabeled, metric = "gower")
gower_mat <- as.matrix(gower_dist)


###Use clustering for label creation
df.mrmr.kmeans <- df.mrmr.unlabeled
df.mrmr.kmeans$label_kmeans <- km$cluster

###Assume that the minority class is 1
df.mrmr.kmeans["label_kmeans"][df_kmeans["label_kmeans"]==2]<-0
df.mrmr.kmeans["label_kmeans"][df_kmeans["label_kmeans"]==1]<-1

table(df.mrmr.kmeans$label_kmeans)


## Data Stratification
### Create train (80%) and test (20%) sets
set.seed(12345)

df_split <- stratified(df.mrmr.kmeans, c('label_kmeans'), 0.8, bothSets=TRUE)

train_kmeans <- df_split$SAMP1
train_kmeans <- as.data.frame(train_kmeans)

test_kmeans <- df_split$SAMP2
test_kmeans<- as.data.frame(test_kmeans) 

# Final Datasets for classification
X_train <- train_kmeans[ , !(names(train_kmeans) %in% c("label_kmeans"))]

y_train <- train_kmeans$label_kmeans
y_train <- factor(y_train)

X_test <- test_kmeans[ , !(names(test_kmeans) %in% c("label_kmeans"))]

y_test <- factor(test_kmeans$label_kmeans)
y_test <- factor(y_test)

######################################
#CLASSIFICATION

###Train

fitControl_knn<- trainControl(method = "cv", number = 5)
model_knn <- caret::train(x = X_train, y = y_train, 
                               method = "knn", 
                               trControl = fitControl_knn_mrmr,
                               tuneLength = 15)

###Evaluate

y.pred.knn.kmeans.mrmr <- predict(model_knn, newdata = X_test)

###Performance
knn_perf <- confusionMatrix(data=y.pred.knn.kmeans.mrmr, reference=y_test, positive = "1")

### Confusion Matrix
cat("Confusion Matrix: ", "\n")
as.table(knn_perf)

### Precision
knn_perf$byClass["Precision"]

### Sensitivity (or Recall)
knn_perf$byClass["Sensitivity"]

### Specificity
knn_perf$byClass["Specificity"]

### Accuracy
knn_perf$overall["Accuracy"]

###ROC curve
roc.curve(y_test, y.pred.knn.kmeans.mrmr)











```




K-Medoids:

```{r}
library("ggfortify")
library("ggplot2")
library(cluster) 
library(factoextra)

set.seed(1)

#Check ideal cluster number
fviz_nbclust(df.train.balanced.no.default, cluster::pam, method="gap_stat")
#perform k-medoids clustering
kmed <- pam(df.train.balanced.no.default, k = 4, metric = "manhattan")
#view results
fviz_cluster(kmed, data = df.train.balanced.no.default, geom = c("point"))

#Compare results
comparison_kmed <-cbind(kmed$cluster,df.train.balanced$default_payment)
cluster_frequency_kmed <- table(comparison_kmed[,1])
dp_frequency_train <- table(comparison_kmed[,2])
prop.table(cluster_frequency_kmed)
prop.table(dp_frequency_train)

#MRMR

library(cluster) 
library(factoextra)

set.seed(1)

#Check ideal cluster number
fviz_nbclust(df.train.mrmr.unlabeled, cluster::pam, method="gap_stat")
#perform k-medoids clustering
kmed <- pam(df.train.mrmr.unlabeled, k = 4, metric = "manhattan")
#view results
fviz_cluster(kmed, data = df.train.mrmr.unlabeled, geom = c("point"))

#Compare results
comparison_kmed <-cbind(kmed$cluster,df.train.mrmr.balanced$default_payment)
cluster_frequency_kmed <- table(comparison_kmed[,1])
dp_frequency_train <- table(comparison_kmed[,2])
prop.table(cluster_frequency_kmed)
prop.table(dp_frequency_train)

```



-Supervised Techniques

Decision Tree:

```{r}

# Decision Tree Model
library(rpart)


val <- df.test

mtree <- rpart(default_payment~., data = df.train.balanced, method="class", control = rpart.control(minsplit = 20, minbucket = 7, maxdepth = 10,usesurrogate = 2, xval =10 ))

mtree

#Plot tree
plot(mtree)
text(mtree)

#Beautify tree
library(rattle)
library(rpart.plot)
library(RColorBrewer)


#view1
prp(mtree, faclen = 0, cex = 0.8, extra = 1)

#view2 - total count at each node
tot_count <- function(x, labs, digits, varlen)
{paste(labs, "\n\nn =", x$frame$n)}

prp(mtree, faclen = 0, cex = 0.8, node.fun=tot_count)

#view3- fancy Plot

fancyRpartPlot(mtree)

############################
########Pruning#############
############################

printcp(mtree)
bestcp <- mtree$cptable[which.min(mtree$cptable[,"xerror"]),"CP"]

# Prune the tree using the best cp.
pruned <- prune(mtree, cp = bestcp)

# Plot pruned tree
prp(pruned, faclen = 0, cex = 0.8, extra = 1)

# confusion matrix (training data)
conf.matrix <- table(df.train$default_payment, predict(pruned,type="class"))
rownames(conf.matrix) <- paste("Actual", rownames(conf.matrix), sep = ":")
colnames(conf.matrix) <- paste("Pred", colnames(conf.matrix), sep = ":")
print(conf.matrix)

#Scoring
library(ROCR)
val1 = predict(pruned, val, type = "prob")
#Storing Model Performance Scores
pred_val <-prediction(val1[,2],val$default_payment)

# Calculating Area under Curve
perf_val <- performance(pred_val,"auc")
perf_val

# Plotting Lift curve
plot(performance(pred_val, measure="lift", x.measure="rpp"), colorize=TRUE)

# Calculating True Positive and False Positive Rate
perf_val <- performance(pred_val, "tpr", "fpr")

# Plot the ROC curve
plot(perf_val, col = "green", lwd = 1.5)

#Calculating KS statistics
ks1.tree <- max(attr(perf_val, "y.values")[[1]] - (attr(perf_val, "x.values")[[1]]))
ks1.tree

# Advanced Plot
prp(pruned, main="Beautiful Tree",
    extra=106, 
    nn=TRUE, 
    fallen.leaves=TRUE, 
    branch=.5, 
    faclen=0, 
    trace=1, 
    shadow.col="gray", 
    branch.lty=3, 
    split.cex=1.2, 
    split.prefix="is ", 
    split.suffix="?", 
    split.box.col="lightgray", 
    split.border.col="darkgray", 
    split.round=.5)

```



Random Forest:

```{r}
library(randomForest)

df.train.balanced$default_payment <- as.factor(df.train.balanced$default_payment)
mydata <- df.train.balanced
set.seed(71)
rf <-randomForest(default_payment~.,data=mydata, ntree=500) 
print(rf)


floor(sqrt(ncol(mydata) - 1))

#Tuning
mtry <- tuneRF(mydata[1:17],mydata$default_payment, ntreeTry=500,
               stepFactor=1.5,improve= 0.05, trace=TRUE, plot=TRUE)
best.m <- mtry[mtry[, 2] == min(mtry[, 2]), 1]
print(mtry)
print(best.m)

#Build model tuned

set.seed(71)
rf <-randomForest(default_payment~.,data=mydata, mtry=best.m, importance=TRUE,ntree=500)
print(rf)

#Evaluate variable importance
importance(rf)
varImpPlot(rf)

```

DBScan
```{r}
install.packages('cluster')
library('cluster')


df.train.pca<-df.train.balanced
df.test.pca<-df.test

#FOR MRMR
  
df.train.mrmr<-read.csv("df.train.mrmr.unlabeled")
df.test.mrmr<-read.csv("df.test.mrmr")

df.train.mrmr<- df.train.mrmr[,-1]
df.test.mrmr<- df.train.mrmr[,-1]


#calculate dissimilarity matrix using gower distance
diss = daisy(x = df.train.mrmr, metric = "gower")
summary(diss)
```
